{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pytesseract as pt\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as xet\n\nfrom glob import glob\nfrom skimage import io\nfrom shutil import copy\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Flatten, Input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\ndef load_and_extract_labels():\n    path = glob('../input/labeled-licence-plates-dataset/dataset/train/*.xml')\n    labels_dict = dict(filepath=[], xmin=[], xmax=[], ymin=[], ymax=[])\n\n    for filename in path:\n        info = xet.parse(filename)\n        root = info.getroot()\n        member_object = root.find('object')\n        labels_info = member_object.find('bndbox')\n        xmin = int(labels_info.find('xmin').text)\n        xmax = int(labels_info.find('xmax').text)\n        ymin = int(labels_info.find('ymin').text)\n        ymax = int(labels_info.find('ymax').text)\n\n        labels_dict['filepath'].append(filename)\n        labels_dict['xmin'].append(xmin)\n        labels_dict['xmax'].append(xmax)\n        labels_dict['ymin'].append(ymin)\n        labels_dict['ymax'].append(ymax)\n\n    df = pd.DataFrame(labels_dict)\n    df.to_csv('labels.csv', index=False)\n    return df\n\ndef preprocess_data(df):\n    filename = df['filepath'][0]\n    \n    def get_filename(filename):\n        filename_image = xet.parse(filename).getroot().find('filename').text\n        filepath_image = os.path.join('../input/labeled-licence-plates-dataset/dataset/train', filename_image)\n        return filepath_image\n\n    image_path = list(df['filepath'].apply(get_filename))\n\n    labels = df.iloc[:, 1:].values\n    data = []\n    output = []\n\n    for ind in range(len(image_path)):\n        image = image_path[ind]\n        img_arr = cv2.imread(image)\n        h, w, d = img_arr.shape\n        \n        # Preprocessing\n        load_image = load_img(image, target_size=(224, 224))\n        load_image_arr = img_to_array(load_image)\n        norm_load_image_arr = load_image_arr / 255.0\n\n        # Normalization to labels\n        xmin, xmax, ymin, ymax = labels[ind]\n        nxmin, nxmax = xmin / w, xmax / w\n        nymin, nymax = ymin / h, ymax / h\n        label_norm = (nxmin, nxmax, nymin, nymax)\n        data.append(norm_load_image_arr)\n        output.append(label_norm)\n\n    X = np.array(data, dtype=np.float32)\n    y = np.array(output, dtype=np.float32)\n\n    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n    return x_train, x_test, y_train, y_test\n\ndef build_object_detection_model():\n    inception_resnet = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n    headmodel = inception_resnet.output\n    headmodel = Flatten()(headmodel)\n    headmodel = Dense(512, activation=\"relu\")(headmodel)\n    headmodel = Dense(256, activation=\"relu\")(headmodel)\n    headmodel = Dense(4, activation='sigmoid')(headmodel)\n\n    model = Model(inputs=inception_resnet.input, outputs=headmodel)\n\n    model.compile(loss=iou_loss, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n    return model\n\ndef train_object_detection_model(model, x_train, y_train, x_test, y_test):\n    tfb = TensorBoard('object_detection')\n    class IoUCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            test_arr = x_test\n            pred_coords = model.predict(test_arr)\n            iou_list = [calculate_iou(true_coords, pred_coords[i]) for i, true_coords in enumerate(y_test)]\n            mean_iou = np.mean(iou_list)\n            print(\"Mean IoU on Validation Set:\", mean_iou)\n\n    history = model.fit(x=x_train, y=y_train, batch_size=10, epochs=150,\n                        validation_data=(x_test, y_test), callbacks=[tfb, IoUCallback()])\n    \n    return history\n\ndef object_detection(path, model):\n    image = load_img(path)\n    image = np.array(image, dtype=np.uint8)\n    image1 = load_img(path, target_size=(224, 224))\n\n    image_arr_224 = img_to_array(image1) / 255.0\n    h, w, d = image.shape\n    test_arr = image_arr_224.reshape(1, 224, 224, 3)\n\n    coords = model.predict(test_arr)\n\n    denorm = np.array([w, w, h, h])\n    coords = coords * denorm\n    coords = coords.astype(np.int32)\n\n    ground_truth_coords = [xmin, ymin, xmax - xmin, ymax - ymin]\n    iou = calculate_iou(ground_truth_coords, coords[0])\n    print(\"IoU:\", iou)\n    \n    xmin, xmax, ymin, ymax = coords[0]\n    pt1 = (xmin, ymin)\n    pt2 = (xmax, ymax)\n    print(\"Bounding Box Coordinates:\", pt1, pt2)\n    cv2.rectangle(image, pt1, pt2, (0, 255, 0), 3)\n    \n    return image, coords\n\ndef extract_text_from_image(image, cods):\n    xmin, xmax, ymin, ymax = cods[0]\n    roi = image[ymin:ymax, xmin:xmax]\n    \n    text = pt.image_to_string(roi)\n    return text\n\ndef calculate_iou(box1, box2):\n    x1, y1, w1, h1 = box1\n    x2, y2, w2, h2 = box2\n\n    intersection_x1 = max(x1, x2)\n    intersection_y1 = max(y1, y2)\n    intersection_x2 = min(x1 + w1, x2 + w2)\n    intersection_y2 = min(y1 + h1, y2 + h2)\n\n    intersection_area = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n\n    box1_area = w1 * h1\n    box2_area = w2 * h2\n\n    union_area = box1_area + box2_area - intersection_area\n\n    iou = intersection_area / union_area\n    return iou\n\ndef iou_loss(y_true, y_pred):\n    true_xmin, true_xmax, true_ymin, true_ymax = tf.unstack(y_true, axis=-1)\n    pred_xmin, pred_xmax, pred_ymin, pred_ymax = tf.unstack(y_pred, axis=-1)\n\n    xmin = K.maximum(true_xmin, pred_xmin)\n    xmax = K.minimum(true_xmax, pred_xmax)\n    ymin = K.maximum(true_ymin, pred_ymin)\n    ymax = K.minimum(true_ymax, pred_ymax)\n\n    intersection_area = K.maximum(0.0, xmax - xmin) * K.maximum(0.0, ymax - ymin)\n\n    true_area = (true_xmax - true_xmin) * (true_ymax - true_ymin)\n    pred_area = (pred_xmax - pred_xmin) * (pred_ymax - pred_ymin)\n    union_area = true_area + pred_area - intersection_area\n\n    iou = intersection_area / (union_area + K.epsilon())\n\n    return 1.0 - iou","metadata":{"execution":{"iopub.status.busy":"2023-07-31T04:45:30.394365Z","iopub.execute_input":"2023-07-31T04:45:30.394823Z","iopub.status.idle":"2023-07-31T04:45:30.451739Z","shell.execute_reply.started":"2023-07-31T04:45:30.394784Z","shell.execute_reply":"2023-07-31T04:45:30.449937Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = load_and_extract_labels()\n\nx_train, x_test, y_train, y_test = preprocess_data(df)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T04:45:56.406847Z","iopub.execute_input":"2023-07-31T04:45:56.407272Z","iopub.status.idle":"2023-07-31T04:46:16.659154Z","shell.execute_reply.started":"2023-07-31T04:45:56.407239Z","shell.execute_reply":"2023-07-31T04:46:16.658097Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = build_object_detection_model()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T04:46:24.185013Z","iopub.execute_input":"2023-07-31T04:46:24.185389Z","iopub.status.idle":"2023-07-31T04:46:31.568417Z","shell.execute_reply.started":"2023-07-31T04:46:24.185358Z","shell.execute_reply":"2023-07-31T04:46:31.567392Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = train_object_detection_model(model, x_train, y_train, x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = '../input/labeled-licence-plates-dataset/dataset/test/104.jpg'\ndetected_image, bounding_box_coords = object_detection(test_image_path, model)\n\nextracted_text = extract_text_from_image(detected_image, bounding_box_coords)\nprint(\"Extracted Text:\", extracted_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.imshow(detected_image)\n    fig.update_layout(width=700, height=500, margin=dict(l=10, r=10, b=10, t=10), xaxis_title='Figure 14')\n    img = np.array(load_img(test_image_path))\n    xmin, xmax, ymin, ymax = bounding_box_coords[0]\n    roi = img[ymin:ymax, xmin:xmax]\n    fig = px.imshow(roi)\n    fig.update_layout(width=350, height=250, margin=dict(l=10, r=10, b=10, t=10), xaxis_title='Cropped image')","metadata":{},"execution_count":null,"outputs":[]}]}