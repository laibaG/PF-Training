{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pytesseract as pt\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as xet\n\nfrom glob import glob\nfrom skimage import io\nfrom shutil import copy\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Flatten, Input, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\ndef generate_preprocess():\n    df = pd.read_csv('/kaggle/input/car-licence/Dataset/train_labels.csv')\n    df['image_name'] = df['filename'].apply(lambda link: os.path.basename(link))\n    df = df.sort_values(by = 'image_name')\n    return df \n   \ndef build_object_detection_model():\n    inception_resnet = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n    headmodel = inception_resnet.output\n    headmodel = Flatten()(headmodel)\n    headmodel = Dense(512, activation=\"relu\")(headmodel)\n    headmodel = Dropout(0.25)(headmodel)\n    headmodel = Dense(256, activation=\"relu\")(headmodel)\n    headmodel = Dropout(0.25)(headmodel)\n    headmodel = Dense(4, activation='sigmoid')(headmodel)\n\n    model = Model(inputs=inception_resnet.input, outputs=headmodel)\n\n    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n    return model\n\ndef train_object_detection_model(model, df):\n    \n    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n    train_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(224, 224),\n        batch_size=16, \n        class_mode='raw',\n        subset=\"training\")\n\n    validation_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(224, 224),\n        batch_size=16, \n        class_mode='raw',\n        subset=\"validation\")\n    \n    tfb = TensorBoard('object_detection')\n    history = model.fit(train_generator, batch_size=16, epochs=100,\n                        validation_data=validation_generator, callbacks=[tfb])\n    \n    return history\n\ndef object_detection(path, model):\n    image = load_img(path)\n    image = np.array(image, dtype=np.uint8)\n    image1 = load_img(path, target_size=(224, 224))\n\n    image_arr_224 = image1 / 255.0\n    h, w, d = image.shape\n    test_arr = image_arr_224.reshape(1, 224, 224, 3)\n\n    coords = model.predict(test_arr)\n\n    denorm = np.array([w, w, h, h])\n    coords = coords * denorm\n    coords = coords.astype(np.int32)\n    \n    coords[:, 0] = np.clip(coords[:, 0], 0, w - 1)\n    coords[:, 1] = np.clip(coords[:, 1], 0, h - 1)\n    coords[:, 2] = np.clip(coords[:, 2], 0, w - 1)\n    coords[:, 3] = np.clip(coords[:, 3], 0, h - 1)\n    \n    xmin, xmax, ymin, ymax = coords[0]\n    pt1 = (xmin, ymin)\n    pt2 = (xmax, ymax)\n    print(\"Bounding Box Coordinates:\", pt1, pt2)\n    cv2.rectangle(image, pt1, pt2, (0, 255, 0), 3)\n    \n    return image, coords\n\ndef extract_text_from_image(image, cods):\n    xmin, xmax, ymin, ymax = cods[0]\n    roi = image[ymin:ymax, xmin:xmax]\n    \n    text = pt.image_to_string(roi)\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:10.372846Z","iopub.execute_input":"2023-08-01T18:27:10.374595Z","iopub.status.idle":"2023-08-01T18:27:11.560350Z","shell.execute_reply.started":"2023-08-01T18:27:10.374518Z","shell.execute_reply":"2023-08-01T18:27:11.559249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = generate_preprocess()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:11.563035Z","iopub.execute_input":"2023-08-01T18:27:11.563405Z","iopub.status.idle":"2023-08-01T18:27:11.597603Z","shell.execute_reply.started":"2023-08-01T18:27:11.563369Z","shell.execute_reply":"2023-08-01T18:27:11.596675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_folder = \"/kaggle/input/car-licence/Dataset/Cars/\"\n# Read the image dimensions and normalize the bounding box values\nfor index, row in df.iterrows():\n    image_path = os.path.join(image_folder, row[\"image_name\"])\n    image = cv2.imread(image_path)\n    image_height, image_width, _ = image.shape\n\n    df.at[index, \"xmin\"] = row[\"xmin\"] / image_width\n    df.at[index, \"ymin\"] = row[\"ymin\"] / image_height\n    df.at[index, \"xmax\"] = row[\"xmax\"] / image_width\n    df.at[index, \"ymax\"] = row[\"ymax\"] / image_height\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:11.599159Z","iopub.execute_input":"2023-08-01T18:27:11.599502Z","iopub.status.idle":"2023-08-01T18:27:13.203927Z","shell.execute_reply.started":"2023-08-01T18:27:11.599469Z","shell.execute_reply":"2023-08-01T18:27:13.202711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_object_detection_model()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:13.205590Z","iopub.execute_input":"2023-08-01T18:27:13.206039Z","iopub.status.idle":"2023-08-01T18:27:16.114324Z","shell.execute_reply.started":"2023-08-01T18:27:13.206001Z","shell.execute_reply":"2023-08-01T18:27:16.111614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train_object_detection_model(model, df)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.115786Z","iopub.status.idle":"2023-08-01T18:27:16.116279Z","shell.execute_reply.started":"2023-08-01T18:27:16.116025Z","shell.execute_reply":"2023-08-01T18:27:16.116048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = '/kaggle/input/car-licence/Dataset/Cars/101.jpg'\ndetected_image, bounding_box_coords = object_detection(test_image_path, model)\n\nextracted_text = extract_text_from_image(detected_image, bounding_box_coords)\nprint(\"Extracted Text:\", extracted_text)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.118203Z","iopub.status.idle":"2023-08-01T18:27:16.118709Z","shell.execute_reply.started":"2023-08-01T18:27:16.118449Z","shell.execute_reply":"2023-08-01T18:27:16.118472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.imshow(detected_image)\nfig.update_layout(width=700, height=500, margin=dict(l=10, r=10, b=10, t=10), xaxis_title='Figure 14')\nimg = np.array(load_img(test_image_path))\nxmin, xmax, ymin, ymax = bounding_box_coords[0]\nroi = img[ymin:ymax, xmin:xmax]\nfig = px.imshow(roi)\nfig.update_layout(width=350, height=250, margin=dict(l=10, r=10, b=10, t=10), xaxis_title='Cropped image')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.120717Z","iopub.status.idle":"2023-08-01T18:27:16.121177Z","shell.execute_reply.started":"2023-08-01T18:27:16.120943Z","shell.execute_reply":"2023-08-01T18:27:16.120965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Here I was trying Bayesian Optimization but it was taking too long**##","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom bayes_opt import BayesianOptimization\nfrom functools import partial\n\n# Step 1: Enable GPU support\nphysical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nif len(physical_devices) > 0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\ndef load_and_extract_labels():\n    df = pd.read_csv('/kaggle/input/car-licence/Dataset/train_labels.csv')\n    image_folder = \"/kaggle/input/car-licence/Dataset/Cars/\"\n    df['image_name'] = df['filename'].apply(lambda link: os.path.basename(link))\n    df = df.sort_values(by = 'image_name')\n    # Read the image dimensions and normalize the bounding box values\n    for index, row in df.iterrows():\n        image_path = os.path.join(image_folder, row[\"image_name\"])\n        image = cv2.imread(image_path)\n        image_height, image_width, _ = image.shape\n\n        df.at[index, \"xmin\"] = row[\"xmin\"] / image_width\n        df.at[index, \"ymin\"] = row[\"ymin\"] / image_height\n        df.at[index, \"xmax\"] = row[\"xmax\"] / image_width\n        df.at[index, \"ymax\"] = row[\"ymax\"] / image_height\n    \n    image_path = df['filename'].apply(lambda x: os.path.join('/kaggle/input/car-licence/Dataset/Cars/',os.path.basename(x)))\n    labels = df[['xmin', 'xmax', 'ymin', 'ymax']].values\n    data = []\n    output = []\n\n    for ind in range(len(image_path)):\n        image = image_path[ind]\n        img_arr = cv2.imread(image)\n        if img_arr is None:\n            print(f\"Error: Could not read image {image}\")\n            continue\n        h, w, d = img_arr.shape\n        \n        # Preprocessing\n        load_image = load_img(image, target_size=(299, 299))\n        load_image_arr = img_to_array(load_image)\n        norm_load_image_arr = load_image_arr / 255.0\n\n        # Normalization to labels\n        xmin, xmax, ymin, ymax = labels[ind]\n        nxmin, nxmax = xmin / w, xmax / w\n        nymin, nymax = ymin / h, ymax / h\n        label_norm = (nxmin, nxmax, nymin, nymax)\n        data.append(norm_load_image_arr)\n        output.append(label_norm)\n\n    X = np.array(data, dtype=np.float32)\n    y = np.array(output, dtype=np.float32)\n\n    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n    return df, x_train, x_test, y_train, y_test\n\ndef build_object_detection_model(learning_rate, dense_units, l2_reg):\n    inception_resnet = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n    headmodel = inception_resnet.output\n    headmodel = Flatten()(headmodel)\n    headmodel = Dense(dense_units, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(headmodel)\n    headmodel = Dense(4, activation='sigmoid')(headmodel)\n\n    model = Model(inputs=inception_resnet.input, outputs=headmodel)\n\n    model.compile(loss=iou_loss, optimizer=Adam(learning_rate=learning_rate))\n    return model\n\n# Step 2: Modify the train_evaluate function to take regularization parameters\ndef train_evaluate(learning_rate, batch_size, x_train, y_train, x_test, y_test, dense_units, l2_reg, df):\n    batch_size = int(batch_size)\n\n    model = build_object_detection_model(learning_rate, dense_units, l2_reg)\n    #model.summary()\n\n    datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.1\n    )\n\n    train_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars/\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(299, 299),\n        batch_size=batch_size,\n        class_mode='raw',\n        subset=\"training\",\n        validate_filenames=True  # Add this option to validate image filenames\n    )\n\n    validation_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars/\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(299, 299),\n        batch_size=batch_size,\n        class_mode='raw',\n        subset=\"validation\",\n        validate_filenames=True  # Add this option to validate image filenames\n    )\n\n    if len(train_generator) == 0:\n        raise ValueError(\"No valid images found for training. Check the 'filename' column in the DataFrame.\")\n    \n    if len(validation_generator) == 0:\n        raise ValueError(\"No valid images found for validation. Check the 'filename' column in the DataFrame.\")\n\n    # Set use_multiprocessing=True and workers=2 to use GPU for faster training\n    history = model.fit(\n        train_generator,\n        steps_per_epoch=len(train_generator),\n        epochs=20,\n        validation_data=validation_generator,\n        verbose=1,\n        use_multiprocessing=True,\n        workers=2\n    )\n\n    return history.history[\"val_loss\"][-1]\n\n\ndef calculate_iou(box1, box2):\n    x1_min,y1_min,x1_max,y1_max=box1\n    x2_min,y2_min,x2_max,y2_max=box2\n    \n    xa=max(x1_min,x2_min)\n    ya=max(y1_min,y2_min)\n    xb=min(x1_max,x2_max)\n    yb=min(y1_max,y2_max)\n\n    interArea=max(0,(xb-xa))*max(0,(yb-ya))\n\n    boxAArea=(x1_max-x1_min)*(y1_max-y1_min)\n    boxBArea=(x2_max-x2_min)*(y2_max-y2_min)\n\n    iou=interArea/float(boxAArea+boxBArea-interArea)\n\n    return iou\n\ndef iou_loss(y_true, y_pred):\n    def process_boxes(y):\n        y_shape = tf.shape(y)\n        y = tf.reshape(y, (y_shape[0], -1))\n        \n        min_xy = y[..., 0:2]\n        max_xy = y[..., 2:4]\n        \n        return min_xy, max_xy\n    \n    t_min, t_max = process_boxes(y_true)\n    p_min, p_max = process_boxes(y_pred)\n    \n    xmin = tf.maximum(t_min[..., 0], p_min[..., 0])\n    xmax = tf.minimum(t_max[..., 0], p_max[..., 0])\n    ymin = tf.maximum(t_min[..., 1], p_min[..., 1])\n    ymax = tf.minimum(t_max[..., 1], p_max[..., 1])\n    \n    intersection_area = tf.maximum(0.0, xmax - xmin) * tf.maximum(0.0, ymax - ymin)\n    \n    true_area = (t_max[..., 0] - t_min[..., 0]) * (t_max[..., 1] - t_min[..., 1])\n    pred_area = (p_max[..., 0] - p_min[..., 0]) * (p_max[..., 1] - p_min[..., 1])\n    union_area = true_area + pred_area - intersection_area\n    \n    iou = intersection_area / (union_area + tf.keras.backend.epsilon())\n    \n    return 1.0 - iou\n\n# Step 3: Modify the optimize_hyperparameters function to include dense_units and l2_reg\ndef optimize_hyperparameters(df, x_train, y_train, x_test, y_test):\n    optimizer = BayesianOptimization(\n        f=partial(train_evaluate, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test, df=df),\n        pbounds={'learning_rate': (1e-5, 1e-2), 'batch_size': (16, 64), 'dense_units': (64, 512), 'l2_reg': (0.01, 0.1)},\n        random_state=0,\n    )\n\n    optimizer.maximize(n_iter=5)\n\n    best_params = optimizer.max['params']\n    best_params['batch_size'] = int(best_params['batch_size'])\n    best_params['dense_units'] = int(best_params['dense_units'])\n\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:08:42.675741Z","iopub.execute_input":"2023-08-01T19:08:42.676109Z","iopub.status.idle":"2023-08-01T19:08:53.075100Z","shell.execute_reply.started":"2023-08-01T19:08:42.676078Z","shell.execute_reply":"2023-08-01T19:08:53.074086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, x_train, x_test, y_train, y_test = load_and_extract_labels()\nbest_params = optimize_hyperparameters(df, x_train, y_train, x_test, y_test)\nprint(\"Best Hyperparameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:08:57.584522Z","iopub.execute_input":"2023-08-01T19:08:57.585536Z","iopub.status.idle":"2023-08-01T19:56:38.875140Z","shell.execute_reply.started":"2023-08-01T19:08:57.585498Z","shell.execute_reply":"2023-08-01T19:56:38.872315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = best_params['learning_rate']\nbatch_size = best_params['batch_size']\ndense_units = best_params['dense_units']\nl2_reg = best_params['l2_reg']\n\n# Train the model with the best hyperparameters\nmodel = build_object_detection_model(learning_rate, dense_units, l2_reg)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.130066Z","iopub.status.idle":"2023-08-01T18:27:16.130542Z","shell.execute_reply.started":"2023-08-01T18:27:16.130303Z","shell.execute_reply":"2023-08-01T18:27:16.130325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.1\n    )\n\n    train_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars/\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(299, 299),\n        batch_size=batch_size,\n        class_mode='raw',\n        subset=\"training\",\n        validate_filenames=True  # Add this option to validate image filenames\n    )\n\n    validation_generator = datagen.flow_from_dataframe(\n        df,\n        directory=\"/kaggle/input/car-licence/Dataset/Cars/\",\n        x_col=\"image_name\",\n        y_col=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n        target_size=(299, 299),\n        batch_size=batch_size,\n        class_mode='raw',\n        subset=\"validation\",\n        validate_filenames=True  # Add this option to validate image filenames\n    )","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.132576Z","iopub.status.idle":"2023-08-01T18:27:16.133093Z","shell.execute_reply.started":"2023-08-01T18:27:16.132831Z","shell.execute_reply":"2023-08-01T18:27:16.132855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=50,\n    validation_data=validation_generator,\n    verbose=1,\n    use_multiprocessing=True,\n    workers=2\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.135118Z","iopub.status.idle":"2023-08-01T18:27:16.135591Z","shell.execute_reply.started":"2023-08-01T18:27:16.135352Z","shell.execute_reply":"2023-08-01T18:27:16.135375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_coords = model.predict(x_test)\niou_list = [calculate_iou(true_coords, pred_coords[i]) for i, true_coords in enumerate(y_test)]\nmean_iou = np.mean(iou_list)\nprint(f\"Mean IoU on test set: {mean_iou}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T18:27:16.142317Z","iopub.status.idle":"2023-08-01T18:27:16.143179Z","shell.execute_reply.started":"2023-08-01T18:27:16.142929Z","shell.execute_reply":"2023-08-01T18:27:16.142953Z"},"trusted":true},"execution_count":null,"outputs":[]}]}